{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of SIFT scale transformation uncertatinty\n",
    "0) Specify datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from sift_uncertainty import *\n",
    "\n",
    "scenes = ['Alamo', 'Ellis_Island', 'Madrid_Metropolis', 'NYC_Library', 'Piazza_del_Popolo', 'Roman_Forum', 'Tower_of_London', 'Union_Square', 'Vienna_Cathedral', 'Yorkminster']\n",
    "scales = [3.97745, 0.94967, 14.44161, 6.95844, 6.25074, 24.38904, 15.72399, 6.85125, 15.07437, 13.26471]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Load all the keypoints (angles, scales, positions) and GT homographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'sift_a1':[], 'sift_a2': [], 'sift_s1': [], 'sift_s2': [], 'sift_u1': [], 'sift_u2': [], 'gt_H1to2': [], 'gt_Hids': []}\n",
    "for scene, scale in zip(scenes, scales):\n",
    "    data = collect_all(scene, scale, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculate the SIFT scale transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift_s12 = np.array(data['sift_s2']) / np.array(data['sift_s1'])\n",
    "\n",
    "plt.hist(sift_s12, 40, range=(0,6))\n",
    "plt.xlabel(r'The detector scale transformation $r_i$')\n",
    "plt.ylabel('Occurrence')\n",
    "plt.title('Histogram of the detector scale transformation')\n",
    "plt.yscale('log')\n",
    "plt.savefig('histogram_of_detector_scale_transformation.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Aproximate the $H_i$ localy by the affinity matrix $A_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACs = [[] for i in range(len(data['sift_a1']))]\n",
    "\n",
    "H2pts_ids = [[] for j in range(len(data['gt_Hids']))]\n",
    "for j,x in enumerate(data['gt_Hids']):\n",
    "    H2pts_ids[x].append(j)\n",
    "\n",
    "for i in tqdm(range(len(data['gt_H1to2']))):\n",
    "    ids = H2pts_ids[i]\n",
    "    H = data['gt_H1to2'][i]\n",
    "    u1 = np.array([data['sift_u1'][j] for j in ids])\n",
    "    u2 = np.array([data['sift_u2'][j] for j in ids])\n",
    "    ACs_arr = affines_from_homography(H, u1, u2)\n",
    "    for j, id in enumerate(ids):\n",
    "        ACs[id] = ACs_arr[j,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Decompose $A_i$ it to the angles by QT, SVD, and exponential analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_a12_svd, gt_a12_logm, gt_s12, cond_num_svd, shear_mag_logm = decompose_affines(ACs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Filter the scale transformations with condition number > 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = np.array(cond_num_svd) < 1.2\n",
    "sift_s12_filtered = np.array(sift_s12)[filter]\n",
    "gt_s12_filtered = np.array(gt_s12)[filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Calculate the translation scale error & filter outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_s12 = sift_s12_filtered / gt_s12_filtered\n",
    "\n",
    "plt.hist(d_s12, 40, range=(0.25,1.75))\n",
    "plt.xlabel(r'The detector scale transformation error $\\Delta_r$')\n",
    "plt.ylabel('Occurrence')\n",
    "plt.title(r'Histogram of $\\Delta_r$ before filtering outliers')\n",
    "plt.show()\n",
    "\n",
    "d_s12_filter = (d_s12 > 0.5) & (d_s12 < 2)     # filter points with larger error than 50%\n",
    "wd_ls12 = np.log(d_s12[d_s12_filter]) / gt_s12_filtered[d_s12_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Plot the histograms of scale transformation errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(d_s12, 40, range=(0.25,1.75))\n",
    "plt.xlabel(r'$\\Delta_{r_i}}$')\n",
    "plt.ylabel('Occurrence')\n",
    "plt.title(r'Histogram of the scale transformation error')\n",
    "plt.savefig('histogram_of_scale_transformation_error.png', dpi=100)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(wd_ls12, 40, range=(-0.75,0.75))\n",
    "plt.xlabel(r'$\\rho_i$')\n",
    "plt.ylabel('Occurrence')\n",
    "plt.title('Histogram of weighted log-scale transformation error')\n",
    "plt.savefig('histogram_of_weighted_logscale_transformation_error.png', dpi=100)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('sift_uncertatinty')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f53f0d87da01e253ece14572a760ac96bfee25eb92f2afbd373dcb1f4950a535"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
